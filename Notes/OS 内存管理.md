# OS 内存管理

## 一、存储管理基础

### 1.存储器硬件

#### 基本硬件与发展

​		功能——保存数据；发展目标——高速、大容量、小体积。目前有两类比较重要的存储器硬件。

​		**SRAM（静态存储器）：**读写速度快、生产成本高，多用于容量较小的高速缓冲存储器（Cache）。

​		**DRAM（动态存储器）：**读写速度慢、集成度高、生产成本低，多用于容量大的存储器。DRAM容易失电，故而需要定期刷新。

​		两者各有用武之处。然而我们需要注意的是，即便我们能够制造出访问速度快或者存储密度大的存储器件，而这两者往往是不可兼得的。现在存储技术正在往这个方面进行突破。

### 2.存储组织

​		在存储技术和CPU寻址技术之间达到平衡，使各层次的存储器都处于"均衡的繁忙状态"。

### 3.存储层次结构

​		计算机的存储是具有一定的层次结构的，其"距离CPU越近"，则其速度应越快；否则容量应大，用于存放数据。

### 4.认识存储管理

#### 两个基本概念

​		**地址空间：**源程序经过编译后得到的目标程序，存在于它所限定的逻辑地址范围内。这个范围称为地址空间，地址空间是**逻辑地址的集合**。

​		**存储空间：**存储空间是指主存中一系列存储信息的物理单元的集合，这些单元的编号称
为物理地址或绝对地址。简言之，存储空间是**物理地址的集合**。

#### 为什么进行存储管理

​		软件对存储的需求增长远快于存储器的增长。如果不对物理存储进行管理，软件会大量占用存储资源。

#### 存储管理的需求

- **支持多道程序和多用户系统**
- **充分利用内存**
- **方便用户使用：OS自动加载程序，对用户透明**
- **较大的逻辑运行空间：不局限于物理内存大小**
- **存储保护与共享**

​		这些需求在存储管理技术中都有相应的办法解决。根据这些需求，我们可以归纳出存储管理需要做到的几大主要功能：存储分配和回收、共享和保护、存储容量扩充等。

​		**分配和回收：**用户请求则分配内存、用户退出则回收内存。利用数据结构完成。

​		**扩充容量：**需要扩充用户编程的容量。通过MMU内存控制单元，利用交换技术和虚拟存储技术解决。

​		**共享：**让多个进程在内存中的相同区域进行代码、数据共享，可以节约空间。

​		**保护：**让多道程序同时运行时又不相互干扰，防止越界、越权行为。

#### 存储管理的数据结构：位图与链表

​		**位图：**给每个分配单元分配一位，用0标记其闲置，用1标记其被占用。

​		**链表：**将分配单元按是否闲置链接，首节点标记其是否被占用。

​		两种标记方法各有优缺点，位图的空间和时间开销都比较小，但是其容错率低；链表的时空开销大，不过容错率高。

​		下面举例比较位图和链表的存储。设内存大小为128MB，即2^27字节；再设每个内存分配单元大小为n字节，内存包含交替的数据区和空闲区，每个区均为64KB且链表的每个结点需要32位的内存地址。

​		**对于位图**——每个分配空间都需要一位存储空间，则需要2^27/n位空间，即2^24/n字节的空间。

​		**对于链表**—— 存在2^27/2^16=2^11个结点，每个节点需要32位空间，节点共占用2^13字节的内存空间。

​		可见，某些条件下，分配空间的大小n会影响位图与链表的空间开销。

#### 存储分配的三种方式

- 直接指定：程序员编程或者编译程序尽心编译时所用的是实际地址。
- 静态分配：程序员编程时，或由编译程序产生的目的程序，均可从其地址空间的零地址开始，在加载程序时确定其在主存中的位置。
- 动态分配：采用逻辑地址，程序在存储空间中的位置在装入时确定。可以手动申请或释放空间。

### 5.连续分配存储管理方式

#### 单一连续区存储管理

​		将内存分为**系统区、用户区**。应用程序载入用户区且可使用用户区全部空间。

​		这种存储管理适用于简单的单用户、单任务的OS，简单且易于管理；但是它易造成内存和性能的浪费。

#### 多用户系统存储器管理——分区式分配

​		思路：将内存分为一些大小异同的**分区**，每个应用程序占用一个或者数个分区，操作系统占用其中一个分区。这种方法适用于多道程序系统和分时系统，支持并发；但难以进行内存分区共享。

​		主要问题：分区内难以利用的空间（内碎片）和分区间难以利用的空间（外碎片）。

​		管理方法：利用分区表或者链表进行管理，使用OS维护数据结构。

##### 固定式分区

​		将存储空间化为若干个任意大小的固定区域，并分配给用户进行作业。

- 大小相同的分区。适于多个相似程序的并发执行。
- 大小不同的分区。按照小、中、大的大小以及合适的比例分区，根据程序大小分配分区作业。

​		**优点：**易于实现、开销小

​		**缺点：**内碎片浪费（载入程序小于分区大小）、分区总数固定限制并发执行程序的数目、大小灵活性差

##### 可变式分区

​		概念：分区的边界可以移动，大小可变。在程序装入时确定分区大小。

​		**优点：**不会产生内碎片。

​		**缺点：**随着多次分配和回收会产生外碎片。

​		需要使用数据结构记录内存的分配和空闲情况。

​		对于可变式分区，为了减少碎片造成的内存空间浪费，人们设计了一系列的内存分配策略用于应对内存分配的变化。

- **最佳适应算法(Best Fit):**为一个作业选择分区时，总是寻找大小最接近其所需存储要求的区域。能够保留大的分区，但是会残存很多小的空闲碎片。
- **最坏适应算法(Worst Fit):**为一个作业选择分区时，总是寻找最大的空白区域。首先分配大的分区，可以使得余下的分区也比较大，可以减少碎片的出现；然而提前占用了大分区的资源，可能无法处理一个较大的作业。
- **首次适应算法(First Fit):**每个空白区域按照其在存储空间中的地址的递增顺序相连，在为作业分配存储区域时，从这个空白链的起始端开始查找，选择第一个满足请求的空白区域。可以优先利用内存低地址部分的空闲分区，但由于低地址部分被不断划分，留下很多细小的分区，这增加了查找可用分区的开销。
- **下次适应算(Next Fit):**把存储空间中空白区构成一个循环链，每次为存储请求查找合适的分区时，总是从上次查找结束的地方开始，只要找到一个足够大的空白区，就将它划分后分配出去。这使得存储空间的使用更加均衡；但也会导致缺乏大的空闲分区。

**空白分区回收：**

​		每当有进程将要从内存中退出的时候，操作系统便会对进程退出后产生的空白空间进行回收。倘若分区相邻，则会将其合并且修改分区表；否则就直接修改分区表。不过实际情况可能复杂一些，这要参见PDF的流程图。

**对可变分区的保护：**

​		为了防止访问越界，我们会设立**界限寄存器**来维护可变分区的上下界限，以防止访问越界。界限寄存器会存放上下界地址信息或事下界以及长度信息，在加载进程前会与将要访问的地址进行匹配。倘若越界，则会陷入中断。

### 6.内存管理：覆盖与交换

​		为了使得内存能够处理更多的任务，我们需要扩充内存容量。一个思路是，将一部分目前使用不到的进程数据放在外存，其他数据放在内存。为此，人们设计了覆盖技术与交换技术。

#### 覆盖

​		覆盖的意思是：一个程序的代码段和数据段按照时间先后占用内存空间。倘若不需要互相调用的程序，则其没有必要同时出现在内存空间当中，故而可以将其中不着急执行的放在外存，待已有程序执行结束，再用其对已有程序占用的内存空间进行覆盖。

​		覆盖技术的缺点是显而易见的，即对于每个程序，为了适应覆盖技术的算法，都必须提前设计好模块间的覆盖关系并且明确调用次序，使得编程方的编程难度大大增加。

#### 交换

​		交换技术简单的说，就是不覆盖已有进程，而是将其替换到外存中。这样的技术和CPU通过快速并发实现宏观并行的方式很相似，可以不用特别关注于程序的结构。当然，让内存进行频繁的交换动作，堆内存的开销也是比较大的。

## 二、内存管理的不同空间

### 1.多道程序使用物理地址可能产生的问题

​		很显然，倘若CPU在物理地址上执行多道程序，在遇到跳转指令时极有可能发生问题：一不小心跳到另一个正在执行的程序的内存空间了。这可能引发程序的崩溃，因为本不相关的程序和内存发生了交叉，其后果是很难预知的。为此，人们提出了很多解决办法。

### 2.重定位

​		先抛开上面的问题不谈。人们将程序加载到内存中时，或许程序加载的位置和物理地址的安排不太相同。为此，人们设计了重定位这一方法，使得内存可以被程序正确链接。按照机时划分，共有三种重定位的方法。

- 编译时重定位：编译时接收到程序加载的物理地址空间，则可直接生成相关代码。但每次更换加载位置都要重新编译。
- 装载时重定位：在装载程序时就将指令的地址和操作数修改为正确的物理地址。这种方法理论可行，但实现起来太过于麻烦。
- 执行时重定位：装载程序时即把程序直接装入内存；程序执行时，基址寄存器存入程序首地址，界限寄存器存放程序的长度。执行时，硬件将自动将逻辑地址加上首地址，并对越界现象进行判断。这是一种动态重定位的方法，其缺点为会在寄存器上增加开销。

### 3.逻辑地址空间

​		逻辑地址空间是对内存的抽象，其本质也是进程用于访问内存的一组地址。但在访问内存前，还是应当将逻辑地址映射为物理地址。完成这一映射，我们需要**存储管理单元MMU**。

### 4.程序的链接和装入

#### 链接

​		链接分为静态链接和动态链接。

- 静态链接：在编译阶段直接将静态库加入到可执行文件中，这会导致可执行文件比较庞大。
- 动态链接：在链接时仅加入一些描述性的信息，在执行时再从系统中加载信息至内存。

​		不过，在进行链接的时候，我们可能需要操作多种多样的文件：`.c`、`.h`......在底层，操作系统是如何把这些文件链接起来呢？这就需要介绍ELF文件格式了。

#### ELF文件格式

​		ELF文件格式是由C语言定义的，主要用到了结构体的定义方法。其作为一种非常底层的文件格式，很好地连接了二进制编码和链接文件。具体的功能在实验中已经有介绍，这里就不多赘述了。

## 三、页式内存管理

### 1.程序、进程和作业

​		程序、进程、作业存在着明显的区别。

- 程序是静止的、存放在磁盘上的可执行文件。
- 进程是动态的，包括程序和数据集。进程分为系统进程和用户进程。
- 作业是用户需要计算机完成的某项任务。

​		程序一般可以看做进程的一部分，进程一般可以看做作业的一部分。当然他们可以独立存在。

### 2.分页式存储管理的基本思想

​		连续存储容易出现碎片，浪费内存空间。英国曼彻斯特大学提出了页式管理的方法，通过硬件MMU实现页式管理。分页式管理也派生出了很多管理的方法。后面首先介绍简单的纯分页系统：不具备页面对换功能和虚拟存储器功能的存储系统。

### 3.基本概念以及一级页表

- 页：将每个作业的地址分成大小相等的片，称为页面。现代操作系统中页面大小一般为4KB
- 存储块：在分页存储管理系统中，把主存的存储空间也分成与页面相同大小的片，这些片称为存储块，或称为**页框（Frame）**。同样从0开始编号
- 页表：为了便于在内存中找到每个页面所对应的内存块，分页系统为每个进程配置一张页表用于查询。

​		下面讲解一些问题。

​		**为什么页面的大小是4KB？**页面较小的时候，确实能够减少内存碎片，但由于每个进程都占用了更多的页，故而需要更多空间存储页表、需要更多时间更换页；页面较大的时候，虽然页表所占空间减小且换出速度变快，但碎片内存也变多了。不如说，4KB的页大小是一个折中的方案。

​		**页表是怎么回事儿？**页表的作用已经做了介绍。页表存放在内存当中，用于记录进程的内存分配情况，并实现进程运行时的动态重定位。存在页表时，访问一个数据需要方位内存两次（先在内存中访问页表，再访问内存的数据）。页表的基地址和长度由页表寄存器给出。

​		**逻辑地址和虚拟地址？**经常在不同的PPT和书本上看到这两个表述，它们用法的相似性总是会让我产生疑问。经过查询一些资料，发现在日常使用中可以将它们看作同一样东西。

​		**逻辑地址到物理地址的转换？**可以用下面的图辅助理解。

![5491649300612_.pic](/Users/enqurance/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/8595b9ac6731cc4fd34dd896c9aacf68/Message/MessageTemp/9e20f478899dc29eb19741386f9343c8/Image/5491649300612_.pic.jpg)

​		取出逻辑地址中的页号，进入内存中的页表进行查询。倘若查询成功则从页表中取出块号，和逻辑地址的页内偏移拼接，得到物理地址。

​		上面的图例是最简单的页表的图例：一级页表。只需要查一张表就可以获得块号，进行地址装载。然而，一级页表结构简单，也有很大的问题。倘若逻辑地址过大，那么仅仅是一个页表就需要占用几十兆的连续内存空间，查询的速度也会下降。这是难以容忍的，所以人们发明了两级页表的页表结构。

### 4.两级页表



